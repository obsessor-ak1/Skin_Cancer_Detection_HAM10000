{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13627357,"sourceType":"datasetVersion","datasetId":8660191}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detection with VGG2\nIn this notebook, we are using VGG16 for classification. This time image augmentation is performed beforehand on the dataset, so no need for weighed random sampling.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install git+https://github.com/obsessor-ak1/Skin_Cancer_Detection_HAM10000.git --no-deps --force-reinstall --no-cache-dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:00:31.709680Z","iopub.execute_input":"2025-11-07T11:00:31.710276Z","iopub.status.idle":"2025-11-07T11:00:41.651983Z","shell.execute_reply.started":"2025-11-07T11:00:31.710245Z","shell.execute_reply":"2025-11-07T11:00:41.651299Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/obsessor-ak1/Skin_Cancer_Detection_HAM10000.git\n  Cloning https://github.com/obsessor-ak1/Skin_Cancer_Detection_HAM10000.git to /tmp/pip-req-build-talr7ey0\n  Running command git clone --filter=blob:none --quiet https://github.com/obsessor-ak1/Skin_Cancer_Detection_HAM10000.git /tmp/pip-req-build-talr7ey0\n  Resolved https://github.com/obsessor-ak1/Skin_Cancer_Detection_HAM10000.git to commit c6658e1b657c9cc7eac19ba0a2b2ec41dae73cb7\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: skin_cancer_detection\n  Building wheel for skin_cancer_detection (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for skin_cancer_detection: filename=skin_cancer_detection-0.1.0-py3-none-any.whl size=15719 sha256=f91d657775abadedc4a5cda986f9a6a5935d722fcf9274bd20e0a67b42fc21f4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3yijj3pq/wheels/1c/73/8d/15507a4fb68edbf3c8bf56d26a749022d0075ab6b50ec069ff\nSuccessfully built skin_cancer_detection\nInstalling collected packages: skin_cancer_detection\nSuccessfully installed skin_cancer_detection-0.1.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from functools import partial\nimport os\n\nimport kagglehub\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision.io import read_image\nfrom torchvision.transforms import v2 as tfs\nfrom torchvision.datasets import ImageFolder\n\nfrom exp_tools.basic_utils import init_module\nfrom exp_tools.metrics import ham10000_precision, ham10000_recall\nfrom exp_tools.training.trainer import Trainer\nfrom exp_tools.modules import vgg_layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:00:44.190495Z","iopub.execute_input":"2025-11-07T11:00:44.191175Z","iopub.status.idle":"2025-11-07T11:00:52.962079Z","shell.execute_reply.started":"2025-11-07T11:00:44.191152Z","shell.execute_reply":"2025-11-07T11:00:52.961440Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Loading the Dataset\nFirst, let's load the dataset from the image folders.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64\nnormalization = tfs.Normalize(\n    mean=[0.5, 0.5, 0.5],\n    std=[0.5, 0.5, 0.5]\n)\ntrain_transform = tfs.Compose([\n    tfs.ToImage(),\n    tfs.ToDtype(torch.float32, scale=1.0),\n    normalization\n])\ntest_transform = tfs.Compose([\n    tfs.ToImage(),\n    tfs.Resize((224, 224)),\n    tfs.ToDtype(torch.float32, scale=1.0),\n    normalization\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:00:58.349780Z","iopub.execute_input":"2025-11-07T11:00:58.350227Z","iopub.status.idle":"2025-11-07T11:00:58.355695Z","shell.execute_reply.started":"2025-11-07T11:00:58.350204Z","shell.execute_reply":"2025-11-07T11:00:58.355119Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"path = kagglehub.dataset_download(\"ak11chp/ham10000-augmented8000-1\")\ntrainset = ImageFolder(\n    os.path.join(path, \"HMNIST_AUG\", \"train\"),\n    transform=train_transform,\n    target_transform=torch.tensor,\n    loader=read_image\n)\ntestset = ImageFolder(\n    os.path.join(path, \"HMNIST_AUG\", \"test\"),\n    transform=test_transform,\n    target_transform=torch.tensor,\n    loader=read_image\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:01:00.590012Z","iopub.execute_input":"2025-11-07T11:01:00.590738Z","iopub.status.idle":"2025-11-07T11:01:43.380622Z","shell.execute_reply.started":"2025-11-07T11:01:00.590716Z","shell.execute_reply":"2025-11-07T11:01:43.380002Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\ntest_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:02:43.569107Z","iopub.execute_input":"2025-11-07T11:02:43.569690Z","iopub.status.idle":"2025-11-07T11:02:43.573731Z","shell.execute_reply.started":"2025-11-07T11:02:43.569671Z","shell.execute_reply":"2025-11-07T11:02:43.572950Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Training the Model\nNow, we are going to load our vgg16 model and train it.","metadata":{}},{"cell_type":"code","source":"class VGG16_BN(torch.nn.Module):\n    \"\"\"A customized vgg 16 model.\"\"\"\n    def __init__(self, num_classes=7, dropout=0.5):\n        super().__init__()\n        self.features = torch.nn.Sequential(\n            vgg_layers.make_blocks(3, 64, 2, end_1x1=True, with_bn=True),\n            vgg_layers.make_blocks(64, 128, 2, end_1x1=True, with_bn=True),\n            vgg_layers.make_blocks(128, 256, 3, end_1x1=True, with_bn=True),\n            vgg_layers.make_blocks(256, 512, 3, end_1x1=True, with_bn=True),\n            vgg_layers.make_blocks(512, 512, 3, end_1x1=True, with_bn=True)\n        )\n        self.pool = torch.nn.AdaptiveAvgPool2d((7, 7))\n        self.classifier = vgg_layers.get_classifier(\n            num_classes=num_classes,\n            dropout=dropout\n        )\n\n    def forward(self, X):\n        X = self.features(X)\n        X = self.pool(X)\n        X = torch.flatten(X, start_dim=1)\n        X = self.classifier(X)\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:02:47.602395Z","iopub.execute_input":"2025-11-07T11:02:47.602656Z","iopub.status.idle":"2025-11-07T11:02:47.608901Z","shell.execute_reply.started":"2025-11-07T11:02:47.602639Z","shell.execute_reply":"2025-11-07T11:02:47.608067Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = VGG16_BN(num_classes=7)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:02:51.437290Z","iopub.execute_input":"2025-11-07T11:02:51.437826Z","iopub.status.idle":"2025-11-07T11:02:52.570945Z","shell.execute_reply.started":"2025-11-07T11:02:51.437800Z","shell.execute_reply":"2025-11-07T11:02:52.570313Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"VGG16_BN(\n  (features): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (1): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (2): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (3): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (4): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n  )\n  (pool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=7, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"metrics = {\n    \"accuracy\": accuracy_score,\n    \"average_precision\": partial(precision_score, average=\"macro\", zero_division=0.0),\n    \"average_recall\": partial(recall_score, average=\"macro\", zero_division=0.0),\n    \"precision\": ham10000_precision,\n    \"recall\": ham10000_recall\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:02:58.087262Z","iopub.execute_input":"2025-11-07T11:02:58.087538Z","iopub.status.idle":"2025-11-07T11:02:58.091394Z","shell.execute_reply.started":"2025-11-07T11:02:58.087515Z","shell.execute_reply":"2025-11-07T11:02:58.090626Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"trainset.class_to_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:03:02.447202Z","iopub.execute_input":"2025-11-07T11:03:02.447717Z","iopub.status.idle":"2025-11-07T11:03:02.452602Z","shell.execute_reply.started":"2025-11-07T11:03:02.447696Z","shell.execute_reply":"2025-11-07T11:03:02.451793Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"weights = torch.tensor([5.0 if cls == \"mel\" else 1.0 for cls in trainset.classes], device=\"cuda\") # higher weight for melanoma class\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2, eps=0.1)\ncriterion = torch.nn.CrossEntropyLoss(weight=weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:03:10.346913Z","iopub.execute_input":"2025-11-07T11:03:10.347429Z","iopub.status.idle":"2025-11-07T11:03:10.565775Z","shell.execute_reply.started":"2025-11-07T11:03:10.347407Z","shell.execute_reply":"2025-11-07T11:03:10.564992Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"trainer = Trainer(\n    max_epochs=10, device=\"cuda\", metrics=metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:03:30.967690Z","iopub.execute_input":"2025-11-07T11:03:30.968382Z","iopub.status.idle":"2025-11-07T11:03:30.971876Z","shell.execute_reply.started":"2025-11-07T11:03:30.968359Z","shell.execute_reply":"2025-11-07T11:03:30.971282Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"%%time\ntrainer.fit(model, criterion, optimizer, train_loader, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T11:03:32.137319Z","iopub.execute_input":"2025-11-07T11:03:32.137594Z","execution_failed":"2025-11-07T13:33:31.169Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 1.2730767427853176\nVal loss: 2.414516713514746\nEpoch 2/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 0.9372495118209294\nVal loss: 2.6466434244140684\nEpoch 3/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 0.8097257800442832\nVal loss: 2.5032690970862848\nEpoch 4/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 0.6956926997389112\nVal loss: 2.943629527946867\nEpoch 5/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 0.6260288433006832\nVal loss: 2.579224190072393\nEpoch 6/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 0.5582365260635104\nVal loss: 2.5285801444237292\nEpoch 7/10\n[--------------------------------------------------] - batch: 875/875 - 100.00 complete\nTrain loss: 0.5139570125171117\nVal loss: 2.6058144243273285\nEpoch 8/10\n[-----------------------------------...............] - batch: 619/875 - 70.74 complete","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"trainer.current_history.plot_history()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-05T23:59:02.279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T10:55:09.610908Z","iopub.execute_input":"2025-11-07T10:55:09.611730Z","iopub.status.idle":"2025-11-07T10:55:09.705598Z","shell.execute_reply.started":"2025-11-07T10:55:09.611704Z","shell.execute_reply":"2025-11-07T10:55:09.704829Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}